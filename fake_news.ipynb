{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "caminho_corpus = 'Fake.br-Corpus/full_texts'\n",
    "\n",
    "dataset = pd.read_csv('Fake.br-Corpus\\preprocessed\\pre-processed.csv', sep=',')\n",
    "\n",
    "\n",
    "def pre_processar(dataframe: pd.DataFrame):\n",
    "    dataframe[\"label\"] = dataframe[\"label\"].apply(lambda x: 1.0 if x == \"true\" else 0.0)\n",
    "    dataframe.rename(columns={\"preprocessed_news\": \"text\"}, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "    \n",
    "dataframe_pre_processado = pre_processar(dataset)\n",
    "\n",
    "print(dataframe_pre_processado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataframe_pre_processado[\"text\"], dataframe_pre_processado[\"label\"], random_state=42)\n",
    "\n",
    "print(f\"Notícias verdadeiras (treino): {y_train.count(0)}\")\n",
    "print(f\"Notícias falsas (treino): {y_train.count(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "tokenizador = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "modelo = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class FakeNewsDetector:\n",
    "    def __init__(self):\n",
    "        self.tokenizador = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
    "        self.modelo = BertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=2)\n",
    "        self.gerador_contexto = pipeline('text-generation', model='Qwen/Qwen2.5-7B')\n",
    "\n",
    "    def gerar_contexto(self, texto_noticia):\n",
    "        prompt = f\"\"\"\n",
    "        Dado o teor desta notícia, gere um contexto local, geográfico e temporal \n",
    "        incluindo datas e acontecimentos importantes, em no máximo um parágrafo:\n",
    "\n",
    "        {texto_noticia}\n",
    "        \"\"\"\n",
    "        \n",
    "        contexto = self.gerador_contexto(\n",
    "            prompt,\n",
    "            max_new_tokens=150,\n",
    "            temperature=0.7,\n",
    "            do_sample=True\n",
    "        )[0]['generated_text']\n",
    "\n",
    "        return contexto.split('Parágrafo:')[-1].strip()\n",
    "\n",
    "    def processar_dados(self, dataframe):\n",
    "        # Adiciona contexto gerado\n",
    "        dataframe['contexto'] = dataframe['text'].apply(self.gerar_contexto)\n",
    "        \n",
    "        # Combina texto original com contexto\n",
    "        dataframe['texto_ampliado'] = dataframe.apply(\n",
    "            lambda x: f\"CONTEXTO: {x['contexto']}\\n\\nNOTÍCIA: {x['text']}\", \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        return dataframe\n",
    "\n",
    "    class NewsDataset(Dataset):\n",
    "        def __init__(self, textos, rotulos, tokenizador, max_len=256):\n",
    "            self.textos = textos\n",
    "            self.rotulos = rotulos\n",
    "            self.tokenizador = tokenizador\n",
    "            self.max_len = max_len\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.textos)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            encoding = self.tokenizador.encode_plus(\n",
    "                self.textos[idx],\n",
    "                max_length=self.max_len,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            return {\n",
    "                'input_ids': encoding['input_ids'].flatten(),\n",
    "                'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                'labels': torch.tensor(self.rotulos[idx], dtype=torch.long)\n",
    "            }\n",
    "\n",
    "    def treinar(self, X_train, y_train, X_val, y_val):\n",
    "        train_dataset = self.NewsDataset(X_train, y_train, self.tokenizador)\n",
    "        val_dataset = self.NewsDataset(X_val, y_val, self.tokenizador)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "        # Configuração de treino (com early stopping)\n",
    "        optimizer = torch.optim.AdamW(self.modelo.parameters(), lr=2e-5)\n",
    "        best_f1 = 0\n",
    "        for epoch in range(5):\n",
    "            self.modelo.train()\n",
    "            for batch in train_loader:\n",
    "                outputs = self.modelo(\n",
    "                    input_ids=batch['input_ids'],\n",
    "                    attention_mask=batch['attention_mask'],\n",
    "                    labels=batch['labels']\n",
    "                )\n",
    "                loss = outputs.loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # Validação\n",
    "            val_metrics = self.avaliar(val_loader)\n",
    "            if val_metrics['f1'] > best_f1:\n",
    "                best_f1 = val_metrics['f1']\n",
    "                torch.save(self.modelo.state_dict(), 'melhor_modelo.pt')\n",
    "\n",
    "\n",
    "# Pipeline completo\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('Fake.br-Corpus/preprocessed/pre-processed.csv')\n",
    "    \n",
    "    df.rename(columns={\"preprocessed_news\": \"text\"}, inplace=True)\n",
    "    \n",
    "    df['label'] = df['label'].map({'true': 1, 'fake': 0})\n",
    "    \n",
    "    detector = FakeNewsDetector()\n",
    "\n",
    "    df_processado = detector.processar_dados(df)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df_processado['texto_ampliado'],\n",
    "        df_processado['label'],\n",
    "        test_size=0.2,\n",
    "        stratify=df_processado['label']\n",
    "    )\n",
    "    \n",
    "    detector.treinar(X_train.tolist(), y_train.tolist(), X_val.tolist(), y_val.tolist())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classificar_noticia(texto, modelo, tokenizador, dispositivo):\n",
    "#     modelo.eval()  \n",
    "#     encoding = tokenizador.encode_plus(\n",
    "#         texto,\n",
    "#         add_special_tokens=True,\n",
    "#         max_length=128,\n",
    "#         return_token_type_ids=False,\n",
    "#         padding='max_length',\n",
    "#         truncation=True,\n",
    "#         return_attention_mask=True,\n",
    "#         return_tensors='pt',\n",
    "#     )\n",
    "#     input_ids = encoding['input_ids'].to(dispositivo)\n",
    "#     attention_mask = encoding['attention_mask'].to(dispositivo)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         saidas = modelo(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         _, predicao = torch.max(saidas.logits, dim=1)\n",
    "\n",
    "#     return 'Falsa' if predicao.item() == 1 else 'Verdadeira'\n",
    "\n",
    "# texto_novo = \"Alckmin diz que gay por ele PSDB “desembarca”, mas não explica se utilizará o aparelho do filme MIB. O governador de São Paulo, Geraldo Alckmin, assegurou nesta terça (28) que, se assumir a presidência do PSDB, como previsto, o partido “desembarca do governo Michel Temer”. “Eu acho que não tem nenhuma razão o continuar no governo. Já não é de hoje que penso assim. Mas as reformas vão continuar”, acrescentou, em entrevista ao jornalista José Luiz Datena, na Rádio Bandeirantes. Ele já foi escolhido para ser presidente nacional do PSDB após uma aliança tucana que busca mitigar o clima de caos absoluto no partido. Nomes como Marconi Perillo (GO) e o senador Tasso Jereissati (CE) já desistiram da presidência. O prefeito de Manaus, Arthur Virgílio, no entanto, não gostou do acordo. A atitude de “desembarque” de Alckmin tem a típica mania recente tucana de apelar ao pior tipo de oportunismo. Porém, como Alckmin fará para que as pessoas esquecem que o partido foi aliado do governo atual por tantos meses? Aliás, não fosse a parceria com o PSDB, dificilmente Dilma teria caído. Goste Alckmin ou não, eles estão anexados. A não ser que ele tenha providenciado aquela mesma tecnologia utilizada na série de filmes \"\n",
    "# resultado = classificar_noticia(texto_novo, modelo, tokenizador, dispositivo)\n",
    "# print(f\"A notícia é: {resultado}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(f\"Notícias verdadeiras: {np.sum(y_train == 0)}\")\n",
    "print(f\"Notícias falsas: {np.sum(y_train == 1)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
